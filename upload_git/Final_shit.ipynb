{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d14bdf4-5c48-4dd1-98ae-f11e55b7b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import random, pickle\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization, Add\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Bidirectional, add\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cc740b-a79f-4097-b61f-9cb87386893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_descriptions(desc_file):\n",
    "    def load_doc(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            return file.read()\n",
    "    \n",
    "    def load_descriptions(doc):\n",
    "        mapping = dict()\n",
    "        for line in doc.split('\\n'):\n",
    "            if len(line) < 2: continue\n",
    "            tokens = line.split()\n",
    "            image_id, image_desc = tokens[0], tokens[1:]\n",
    "            image_id = image_id.split('.')[0]\n",
    "            image_desc = ' '.join(image_desc)\n",
    "            if image_id not in mapping:\n",
    "                mapping[image_id] = list()\n",
    "            mapping[image_id].append(image_desc)\n",
    "        return mapping\n",
    "    \n",
    "    def clean_descriptions(descriptions):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        for key, desc_list in descriptions.items():\n",
    "            for i in range(len(desc_list)):\n",
    "                desc = desc_list[i]\n",
    "                desc = tokenizer.tokenize(desc)\n",
    "                desc = [word.lower() for word in desc]\n",
    "                desc = [word for word in desc if len(word) > 1]\n",
    "                desc_list[i] = ' '.join(desc)\n",
    "    \n",
    "    doc = load_doc(desc_file)\n",
    "    descriptions = load_descriptions(doc)\n",
    "    clean_descriptions(descriptions)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9f7798-1de4-44ad-853a-4a9bdee08155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(descriptions):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    all_desc = set()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.update(tokenizer.tokenize(d)) for d in descriptions[key]]\n",
    "    return all_desc\n",
    "\n",
    "# Save descriptions\n",
    "def save_descriptions(descriptions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + ' ' + desc)\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f32572a-fff7-4e9b-978e-a587cf6c6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_feature_extractor():\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    return Model(model.input, model.layers[-2].output)\n",
    "\n",
    "def encode_image(image_path, model):\n",
    "    \"\"\"Encode single image\"\"\"\n",
    "    def preprocess(image_path):\n",
    "        img = image.load_img(image_path, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        return preprocess_input(x)\n",
    "    \n",
    "    img = preprocess(image_path)\n",
    "    return model.predict(img, verbose=0)\n",
    "\n",
    "def encode_images(image_paths, model):\n",
    "    encoded = {}\n",
    "    for img_path in tqdm(image_paths, desc=\"Encoding images\"):\n",
    "        encoded[os.path.basename(img_path)] = encode_image(img_path, model)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092c6a28-2d15-43fd-946f-fa94e77a72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_data(descriptions):\n",
    "    \"\"\"Create tokenizer and vocabulary\"\"\"\n",
    "    all_captions = []\n",
    "    for key, val in descriptions.items():\n",
    "        all_captions.extend(val)\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_captions)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    max_length = max(len(cap.split()) for cap in all_captions)\n",
    "    \n",
    "    return tokenizer, vocab_size, max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a6a40a-7783-4399-b3c9-0a10ddce8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images_to_disk(image_paths, model, output_path=\"image_features.pkl\"):\n",
    "    encoded = {}\n",
    "    for img_path in tqdm(image_paths, desc=\"Encoding images\"):\n",
    "        img_id = os.path.basename(img_path)\n",
    "        feature = encode_image(img_path, model)\n",
    "        encoded[img_id] = feature.squeeze()  # Flatten to 1D\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(encoded, f)\n",
    "    return encoded\n",
    "\n",
    "def load_encoded_images(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8aea76-4468-4891-9993-c16bbd15443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, descriptions, photos, wordtoix, max_length, batch_size=4):\n",
    "        self.descriptions = {k: descriptions[k] for k in descriptions if k in photos}\n",
    "        self.photos = photos\n",
    "        self.wordtoix = wordtoix\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.keys = list(self.descriptions.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.keys) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X1, X2, y = [], [], []\n",
    "        keys = self.keys[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        for key in keys:\n",
    "            photo = self.photos.get(key + '.jpg') or self.photos.get(key)\n",
    "            if photo is None: continue\n",
    "            photo = np.array(photo)\n",
    "            \n",
    "            for desc in self.descriptions[key]:\n",
    "                seq = [self.wordtoix[w] for w in desc.split() if w in self.wordtoix]\n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq = pad_sequences([seq[:i]], maxlen=self.max_length)[0]\n",
    "                    out_seq = seq[i]\n",
    "                    X1.append(photo)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "                    \n",
    "        return (np.array(X1), np.array(X2)), np.array(y)  \n",
    "\n",
    "\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a26179-5cc7-423b-ae97-591dcbf8f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_caption_model(vocab_size, max_length):\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "\n",
    "    decoder1 = Add()([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def train_model(model, data_gen, train_descriptions, epochs=40, batch_size=6):\n",
    "    steps_per_epoch = len(train_descriptions) // batch_size\n",
    "    history = model.fit(\n",
    "        data_gen,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c497ba0-8b33-45df-83f0-c3b50f732c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(model, photo, wordtoix, ixtoword, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for _ in range(max_length):\n",
    "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = ixtoword.get(yhat)\n",
    "        if word is None or word == 'endseq':\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "    return in_text.replace('startseq', '').replace('endseq', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f314733-d69d-4288-9c80-1b6ba9f9527a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c0f363-395c-444c-95a8-4fd0f4d7c529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859abe56-ab0f-45b2-8b38-9d7e630781ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_data(descriptions, tokenizer_save_path=\"tokenizer.pkl\"):\n",
    "    \"\"\"Create tokenizer and vocabulary\"\"\"\n",
    "    all_captions = []\n",
    "    for key, val in descriptions.items():\n",
    "        all_captions.extend(val)\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_captions)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    max_length = max(len(cap.split()) for cap in all_captions)\n",
    "    \n",
    "    # Save tokenizer to file\n",
    "    with open(tokenizer_save_path, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    \n",
    "    return tokenizer, vocab_size, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2be7c4-e584-43f9-8bb5-46e2bb2edb92",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(model_path, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotEqual\u001b[39m\u001b[38;5;124m\"\u001b[39m: tf\u001b[38;5;241m.\u001b[39mnot_equal})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    190\u001b[0m         filepath,\n\u001b[1;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:133\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    130\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m saving_options\u001b[38;5;241m.\u001b[39mkeras_option_scope(use_legacy_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 133\u001b[0m     model \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    134\u001b[0m         model_config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     load_weights_from_hdf5_group(f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m], model)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m     86\u001b[0m     config,\n\u001b[1;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:495\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    490\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(\n\u001b[1;32m    491\u001b[0m     cls_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[0;32m--> 495\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(\n\u001b[1;32m    496\u001b[0m         cls_config,\n\u001b[1;32m    497\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    498\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobject_registration\u001b[38;5;241m.\u001b[39mGLOBAL_CUSTOM_OBJECTS,\n\u001b[1;32m    499\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom_objects,\n\u001b[1;32m    500\u001b[0m         },\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/model.py:582\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional_from_config(\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    584\u001b[0m     )\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/functional.py:551\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 551\u001b[0m     process_layer(layer_data)\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/models/functional.py:519\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     layer \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    520\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    524\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m     86\u001b[0m     config,\n\u001b[1;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:511\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    509\u001b[0m     custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[0;32m--> 511\u001b[0m         deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcls_config)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Add object to shared objects, in case we find it referenced again.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m _shared_object_loading_scope()\u001b[38;5;241m.\u001b[39mset(shared_object_id, deserialized_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1254\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1254\u001b[0m result \u001b[38;5;241m=\u001b[39m api_dispatcher\u001b[38;5;241m.\u001b[39mDispatch(args, kwargs)\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing required positional argument"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc14514-255f-461c-87a3-0a5162dd0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_image_captioning_pipeline():\n",
    "    desc_file = \"/home/abdelraheem/Abdo_Omda/Nlp/Flickr8k.token.txt\"\n",
    "    train_file = \"/home/abdelraheem/Abdo_Omda/Nlp/Flickr_8k.trainImages.txt\"\n",
    "    image_dir = \"/home/abdelraheem/Abdo_Omda/Nlp/Flicker_dataset/Images\"\n",
    "    encoded_features_path = \"/home/abdelraheem/Abdo_Omda/Nlp/encoded_train_features.pkl\"\n",
    "\n",
    "    descriptions = load_and_process_descriptions(desc_file)\n",
    "    train_names_full = open(train_file).read().strip().split('\\n')\n",
    "    train_names = [os.path.splitext(name)[0] for name in train_names_full]\n",
    "    train_img_paths = [os.path.join(image_dir, name) for name in train_names_full]\n",
    "\n",
    "    if not os.path.exists(encoded_features_path):\n",
    "        feature_model = setup_feature_extractor()\n",
    "        encode_images_to_disk(train_img_paths, feature_model, encoded_features_path)\n",
    "    \n",
    "    encoded_train = load_encoded_images(encoded_features_path)\n",
    "    \n",
    "    tokenizer, vocab_size, max_length = prepare_text_data(descriptions, tokenizer_save_path=\"tokenizer.pkl\")\n",
    "    wordtoix = tokenizer.word_index\n",
    "    ixtoword = {v: k for k, v in wordtoix.items()}\n",
    "    \n",
    "    train_descriptions = {k: descriptions[k] for k in train_names if k in descriptions}\n",
    "    train_features = {k: encoded_train[k + '.jpg'] for k in train_names if k + '.jpg' in encoded_train}\n",
    "    \n",
    "    valid_keys = set(train_descriptions.keys()) & set(train_features.keys())\n",
    "    print(f\"Valid keys for training: {len(valid_keys)}\")\n",
    "    \n",
    "    train_descriptions = {k: train_descriptions[k] for k in valid_keys}\n",
    "    train_features = {k: train_features[k] for k in valid_keys}\n",
    "    \n",
    "    data_gen = CaptionDataGenerator(train_descriptions, train_features, wordtoix, max_length, batch_size=6)\n",
    "\n",
    "    # ✅ Fix: define the model before training\n",
    "    model = build_caption_model(vocab_size, max_length)\n",
    "\n",
    "    model.fit(data_gen, epochs=20)\n",
    "    model.save('/home/abdelraheem/Abdo_Omda/Nlp/model_weights/final_model.h5')\n",
    "\n",
    "    feature_model = setup_feature_extractor()\n",
    "    test_img = \"/home/abdelraheem/Abdo_Omda/Nlp/Flicker_dataset/Images/667626_18933d713e.jpg\"\n",
    "    test_feat = encode_image(test_img, feature_model).squeeze()\n",
    "    caption = generate_caption(model, np.expand_dims(test_feat, axis=0), wordtoix, ixtoword, max_length)\n",
    "\n",
    "    plt.imshow(plt.imread(test_img))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Generated: \" + caption)\n",
    "    plt.show()\n",
    "    print(\"Generated Caption:\", caption)\n",
    "\n",
    "run_image_captioning_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d4d465b-bd60-4ce3-9dbc-bfef2918e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: dog is running through the snow of the grass in the grass in the grass with the grass in the grass and white dog is running through the snow of the grass in the\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"/home/abdelraheem/Abdo_Omda/Nlp/model_weights/final_model.h5\"\n",
    "test_img = \"/home/abdelraheem/Abdo_Omda/Nlp/Flicker_dataset/Images/101654506_8eb26cfb60.jpg\"\n",
    "if 'model' not in globals():\n",
    "    model = load_model(model_path, compile=False)\n",
    "    feature_model = setup_feature_extractor()\n",
    "\n",
    "def generate_caption_for_image(img_path):\n",
    "    test_feat = encode_image(img_path, feature_model).squeeze()\n",
    "    caption = generate_caption(model, np.expand_dims(test_feat, axis=0), wordtoix, ixtoword, max_length)\n",
    "    return caption\n",
    "\n",
    "caption = generate_caption_for_image(test_img)\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed3918-2832-43e1-b403-8c1c9f932d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b86c3c-3a0a-4977-afbb-fd1310e4b439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
